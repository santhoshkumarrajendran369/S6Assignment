name: Model Architecture Tests

on:
  push:
    branches: [ main, master ]
  pull_request:
    branches: [ main, master ]

jobs:
  test:
    runs-on: ubuntu-latest
    strategy:
      matrix:
        python-version: [3.8]

    steps:
    - uses: actions/checkout@v4
    
    - name: Set up Python ${{ matrix.python-version }}
      uses: actions/setup-python@v5
      with:
        python-version: ${{ matrix.python-version }}
    
    - name: Install dependencies
      run: |
        python -m pip install --upgrade pip
        pip install pytest
        pip install torch torchvision --index-url https://download.pytorch.org/whl/cpu
        pip install -r requirements.txt
    
    - name: Run Parameter Count Test
      run: |
        python - <<EOF
        import torch
        from model import Net
        model = Net()
        total_params = sum(p.numel() for p in model.parameters() if p.requires_grad)
        print(f'\nTotal Parameters: {total_params:,}')
        assert total_params < 20000, f'Model has {total_params:,} parameters, exceeding 20k limit'
        print('\n✅ Parameter Count Test Passed: Model has less than 20k parameters')
        EOF
    
    - name: Test Batch Normalization
      run: |
        python - <<EOF
        import torch
        import torch.nn as nn
        from model import Net
        model = Net()
        bn_layers = sum(1 for m in model.modules() if isinstance(m, nn.BatchNorm2d))
        print(f'\nBatch Normalization Layers Found: {bn_layers}')
        assert bn_layers > 0, 'No Batch Normalization layers found'
        print('\n✅ Batch Normalization Test Passed: Found {bn_layers} BatchNorm layers')
        EOF
    
    - name: Test Dropout Usage
      run: |
        python - <<EOF
        import torch
        import torch.nn as nn
        from model import Net
        model = Net()
        dropout_layers = [(name, m.p) for name, m in model.named_modules() if isinstance(m, nn.Dropout)]
        print(f'\nDropout Layers Found: {len(dropout_layers)}')
        for name, p in dropout_layers:
            print(f'Layer: {name}, Dropout Rate: {p}')
        assert len(dropout_layers) > 0, 'No Dropout layers found'
        print('\n✅ Dropout Test Passed: Found {len(dropout_layers)} Dropout layers')
        EOF
    
    - name: Test GAP vs FC Layer
      run: |
        python - <<EOF
        import torch
        import torch.nn as nn
        from model import Net
        model = Net()
        fc_layers = sum(1 for m in model.modules() if isinstance(m, nn.Linear))
        print(f'\nFully Connected Layers Found: {fc_layers}')
        assert fc_layers == 0, 'Found Fully Connected layers, should use GAP instead'
        print('\n✅ Architecture Test Passed: No FC layers found, using GAP')
        EOF

    - name: Test Model Accuracy
      run: |
        python - <<EOF
        import torch
        import torch.nn as nn
        import torch.nn.functional as F
        import torch.optim as optim
        from torchvision import datasets, transforms
        from model import Net
        
        def train(model, device, train_loader, optimizer, epoch):
            model.train()
            for batch_idx, (data, target) in enumerate(train_loader):
                data, target = data.to(device), target.to(device)
                optimizer.zero_grad()
                output = model(data)
                loss = F.nll_loss(output, target)
                loss.backward()
                optimizer.step()
                if batch_idx % 100 == 0:
                    print(f'Train Epoch: {epoch} [{batch_idx * len(data)}/{len(train_loader.dataset)} '
                          f'({100. * batch_idx / len(train_loader):.0f}%)]\tLoss: {loss.item():.6f}')

        def test(model, device, test_loader):
            model.eval()
            test_loss = 0
            correct = 0
            with torch.no_grad():
                for data, target in test_loader:
                    data, target = data.to(device), target.to(device)
                    output = model(data)
                    test_loss += F.nll_loss(output, target, reduction='sum').item()
                    pred = output.argmax(dim=1, keepdim=True)
                    correct += pred.eq(target.view_as(pred)).sum().item()

            test_loss /= len(test_loader.dataset)
            accuracy = 100. * correct / len(test_loader.dataset)
            print(f'\nTest set: Average loss: {test_loss:.4f}, Accuracy: {accuracy:.2f}%')
            return test_loss, accuracy

        # Setup device
        device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
        print(f"\nUsing device: {device}")

        # Create data directory if it doesn't exist
        import os
        os.makedirs('../data', exist_ok=True)

        # Load train and test data
        train_loader = torch.utils.data.DataLoader(
            datasets.MNIST('../data', train=True, download=True, transform=transforms.Compose([
                transforms.ToTensor(),
                transforms.Normalize((0.1307,), (0.3081,))
            ])),
            batch_size=128, shuffle=True)

        test_loader = torch.utils.data.DataLoader(
            datasets.MNIST('../data', train=False, download=True, transform=transforms.Compose([
                transforms.ToTensor(),
                transforms.Normalize((0.1307,), (0.3081,))
            ])),
            batch_size=1000, shuffle=True)

        # Initialize model, optimizer, and scheduler
        model = Net().to(device)
        optimizer = optim.SGD(model.parameters(), lr=0.05, momentum=0.9)
        scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=15)

        # Train the model
        print("\nStarting training...")
        for epoch in range(1, 16):
            train(model, device, train_loader, optimizer, epoch)
            test_loss, accuracy = test(model, device, test_loader)
            scheduler.step()

        print(f'\nFinal Test set: Average loss: {test_loss:.4f}, Accuracy: {accuracy:.2f}%')
        assert accuracy > 99.0, f'Model accuracy {accuracy:.2f}% is below 99% threshold'
        print('\n✅ Accuracy Test Passed: Model achieves above 99% accuracy')
        EOF
    
    - name: Generate Test Summary
      if: always()
      run: |
        echo "## Model Architecture Test Results" >> $GITHUB_STEP_SUMMARY
        echo "### Test Requirements:" >> $GITHUB_STEP_SUMMARY
        echo "✓ Total Parameter Count < 20k" >> $GITHUB_STEP_SUMMARY
        echo "✓ Use of Batch Normalization" >> $GITHUB_STEP_SUMMARY
        echo "✓ Use of Dropout" >> $GITHUB_STEP_SUMMARY
        echo "✓ Use of Global Average Pooling (No FC layers)" >> $GITHUB_STEP_SUMMARY
        echo "✓ Model Accuracy > 99%" >> $GITHUB_STEP_SUMMARY
        
        if [ ${{ job.status }} == 'success' ]; then
          echo "### Status: ✅ All Tests Passed" >> $GITHUB_STEP_SUMMARY
        else
          echo "### Status: ❌ Tests Failed" >> $GITHUB_STEP_SUMMARY
        fi
